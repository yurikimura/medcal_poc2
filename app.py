import os
import streamlit as st
from langchain_community.document_loaders import PubMedLoader, ArxivLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_core.documents import Document
from concurrent.futures import ThreadPoolExecutor
import time

# Page configuration
st.set_page_config(
    page_title="Medical Diagnosis Bot",
    page_icon="ğŸ¥",
    layout="wide"
)

# App title and description
st.title("ğŸ¥ å¤šè¨€èªå¯¾å¿œ ç—‡çŠ¶ã‹ã‚‰ç—…åã‚’ç‰¹å®šã™ã‚‹åŒ»ç™‚è¨ºæ–­ãƒœãƒƒãƒˆ")
st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€å…¥åŠ›ã•ã‚ŒãŸç—‡çŠ¶ã‹ã‚‰è€ƒãˆã‚‰ã‚Œã‚‹ç—…åã‚’ææ¡ˆã—ã¾ã™ã€‚
PubMedã¨ArXivã‹ã‚‰æœ€æ–°ã®åŒ»å­¦è«–æ–‡ã‚’æ¤œç´¢ã—ã€å¯èƒ½æ€§ã®ã‚ã‚‹è¨ºæ–­ã‚’æç¤ºã—ã¾ã™ã€‚

**æ³¨æ„**: ã“ã‚Œã¯åŒ»å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿéš›ã®è¨ºæ–­ã«ã¯å¿…ãšåŒ»å¸«ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚
""")

# Sidebar for API key
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("OpenAI API ã‚­ãƒ¼", type="password", 
                           help="è‡ªåˆ†ã®OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        ["gpt-3.5-turbo", "gpt-4o", "gpt-4-turbo"]
    )
    st.markdown("---")
    st.markdown("## ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦")
    st.markdown("""
    ã“ã®ã‚¢ãƒ—ãƒªã¯ç—‡çŠ¶ã«åŸºã¥ã„ã¦è€ƒãˆã‚‰ã‚Œã‚‹ç—…åã‚’ææ¡ˆã—ã¾ã™ã€‚
    1. ç—‡çŠ¶ã‚’å…¥åŠ›è¨€èªã§è¨˜è¿°
    2. å¿…è¦ã«å¿œã˜ã¦æ‚£è€…æƒ…å ±ã‚’è¿½åŠ 
    3. ã€Œè¨ºæ–­é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. PubMedã¨ArXivã‹ã‚‰é–¢é€£ã™ã‚‹è«–æ–‡ãŒæ¤œç´¢ã•ã‚Œã¾ã™
    5. AIãŒè€ƒãˆã‚‰ã‚Œã‚‹ç—…åã¨èª¬æ˜ã‚’æä¾›ã—ã¾ã™
    """)


class MultilingualMedicalBot:
    def __init__(self, api_key, model_name="gpt-3.5-turbo"):
        # OpenAI APIã‚­ãƒ¼ã®è¨­å®š
        os.environ["OPENAI_API_KEY"] = api_key
        
        self.llm = ChatOpenAI(model_name=model_name)
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )

        # ç¿»è¨³ç”¨LLMï¼ˆåŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
        self.translator_llm = ChatOpenAI(model_name=model_name)

    def translate_symptoms_to_english(self, symptoms, source_language="æ—¥æœ¬èª"):
        """
        ç—‡çŠ¶ã‚’è‹±èªã«ç¿»è¨³
        """
        translation_prompt = ChatPromptTemplate.from_template("""
        ã‚ãªãŸã¯åŒ»å­¦ç”¨èªã«ç²¾é€šã—ãŸç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®{source_language}ã®ç—‡çŠ¶ã‚’ã€
        åŒ»å­¦çš„ã«æ­£ç¢ºãªè‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚PubMedã‚„ArXivãªã©ã®åŒ»å­¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§
        æ¤œç´¢ã™ã‚‹éš›ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã€å°‚é–€çš„ãªåŒ»å­¦ç”¨èªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

        ç—‡çŠ¶: {symptoms}

        è‹±èªç¿»è¨³ï¼ˆåŒ»å­¦ç”¨èªï¼‰:
        """)

        # ç¿»è¨³ã‚’å®Ÿè¡Œ
        translation_chain = translation_prompt | self.translator_llm
        result = translation_chain.invoke({
            "source_language": source_language,
            "symptoms": symptoms
        })

        translated = result.content.strip()
        return translated

    def _load_pubmed_docs(self, english_symptoms):
        """PubMedã‹ã‚‰æ–‡çŒ®ã‚’å–å¾—"""
        search_query = f"{english_symptoms} symptoms diagnosis"
        try:
            loader = PubMedLoader(query=search_query)
            documents = loader.load()
            return documents, len(documents)
        except Exception as e:
            st.error(f"PubMedæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return [], 0

    def _load_arxiv_docs(self, english_symptoms, max_docs=5):
        """ArXivã‹ã‚‰æ–‡çŒ®ã‚’å–å¾—"""
        search_query = f"{english_symptoms} symptoms diagnosis medical"

        try:
            loader = ArxivLoader(
                query=search_query,
                load_max_documents=max_docs,
                load_all_available_meta=True
            )
            documents = loader.load()
            return documents, len(documents)
        except Exception as e:
            st.error(f"ArXivæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return [], 0

    def create_knowledge_base(self, symptoms, source_language="æ—¥æœ¬èª", progress_bar=None):
        """
        ç—‡çŠ¶ã«åŸºã¥ã„ã¦PubMedã¨ArXivã‹ã‚‰é–¢é€£æ–‡çŒ®ã‚’æ¤œç´¢ã—ã€çµ±åˆçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
        """
        # ç—‡çŠ¶ã‚’è‹±èªã«ç¿»è¨³
        if progress_bar:
            progress_bar.progress(0.1, text="ç—‡çŠ¶ã‚’è‹±èªã«ç¿»è¨³ä¸­...")
        
        english_symptoms = self.translate_symptoms_to_english(symptoms, source_language)
        
        if progress_bar:
            progress_bar.progress(0.2, text="PubMedã¨ArXivã‹ã‚‰æ–‡çŒ®ã‚’æ¤œç´¢ä¸­...")

        # ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¡æ–¹ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰åŒæ™‚ã«å–å¾—
        with ThreadPoolExecutor(max_workers=2) as executor:
            pubmed_future = executor.submit(self._load_pubmed_docs, english_symptoms)
            arxiv_future = executor.submit(self._load_arxiv_docs, english_symptoms)

            pubmed_docs, pubmed_count = pubmed_future.result()
            arxiv_docs, arxiv_count = arxiv_future.result()

        if progress_bar:
            progress_bar.progress(0.4, text="æ¤œç´¢çµæœã‚’å‡¦ç†ä¸­...")

        # å–å¾—ã—ãŸæ–‡çŒ®ã‚’çµ±åˆ
        all_docs = pubmed_docs + arxiv_docs

        if not all_docs:
            # ã‚¨ãƒ©ãƒ¼ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            all_docs = [Document(
                page_content="ç—‡çŠ¶ã«å¯¾ã™ã‚‹åŒ»å­¦æ–‡çŒ®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šä¸€èˆ¬çš„ãªç—‡çŠ¶ã®èª¬æ˜ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚",
                metadata={"source": "error_message"}
            )]

        # æ–‡çŒ®ã®æƒ…å ±ã‚’è¿”ã™
        pubmed_info = []
        for i, doc in enumerate(pubmed_docs):
            pubmed_info.append({
                "index": i + 1,
                "title": doc.metadata.get('Title', 'ã‚¿ã‚¤ãƒˆãƒ«æƒ…å ±ãªã—'),
                "authors": doc.metadata.get('Authors', 'è‘—è€…æƒ…å ±ãªã—'),
                "pubdate": doc.metadata.get('Publication Date', 'å‡ºç‰ˆæ—¥æƒ…å ±ãªã—')
            })

        arxiv_info = []
        for i, doc in enumerate(arxiv_docs):
            arxiv_info.append({
                "index": i + 1,
                "title": doc.metadata.get('Title', 'ã‚¿ã‚¤ãƒˆãƒ«æƒ…å ±ãªã—'),
                "authors": doc.metadata.get('Authors', 'è‘—è€…æƒ…å ±ãªã—'),
                "published": doc.metadata.get('Published', 'å‡ºç‰ˆæ—¥æƒ…å ±ãªã—')
            })

        if progress_bar:
            progress_bar.progress(0.6, text="ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆä¸­...")

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
        splits = self.text_splitter.split_documents(all_docs)

        # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ
        vectorstore = FAISS.from_documents(splits, self.embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

        if progress_bar:
            progress_bar.progress(0.7, text="è¨ºæ–­æº–å‚™å®Œäº†...")

        return retriever, english_symptoms, pubmed_info, arxiv_info

    def diagnose(self, symptoms, patient_data=None, source_language="æ—¥æœ¬èª", target_language="æ—¥æœ¬èª", progress_bar=None):
        """
        ç—‡çŠ¶ã«åŸºã¥ã„ã¦ç—…åã‚’ç‰¹å®šã—ã€æŒ‡å®šã•ã‚ŒãŸè¨€èªã§å›ç­”
        """
        # æ‚£è€…ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        additional_context = ""
        if patient_data:
            patient_info = "\n".join([f"{k}: {v}" for k, v in patient_data.items() if v])
            if patient_info.strip():
                additional_context = f"æ‚£è€…æƒ…å ±:\n{patient_info}"

        # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆï¼ˆç—‡çŠ¶ã‚’è‹±èªã«ç¿»è¨³ï¼‰
        retriever, english_symptoms, pubmed_info, arxiv_info = self.create_knowledge_base(
            symptoms, source_language, progress_bar
        )

        if progress_bar:
            progress_bar.progress(0.8, text="è¨ºæ–­åˆ†æä¸­...")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆï¼ˆè¨€èªã«å¿œã˜ã¦ï¼‰
        if target_language.lower() == "æ—¥æœ¬èª":
            prompt = ChatPromptTemplate.from_template("""
            ã‚ãªãŸã¯é›£ç—…è¨ºæ–­ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç—‡çŠ¶ã«åŸºã¥ã„ã¦ã€è€ƒãˆã†ã‚‹ç—…åã‚’å…¨ã¦æŒ™ã’ã€ãã®ç†ç”±ã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

            æ‚£è€…ã®ç—‡çŠ¶: {input}
            è‹±èªã«ç¿»è¨³ã•ã‚ŒãŸç—‡çŠ¶: {english_symptoms}

            è¿½åŠ æƒ…å ±: {additional_context}

            ä»¥ä¸‹ã¯å‚è€ƒã¨ãªã‚‹åŒ»å­¦è«–æ–‡ã®æƒ…å ±ã§ã™:
            {context}

            å›ç­”å½¢å¼:
            è€ƒãˆã‚‰ã‚Œã‚‹ç—…åï¼š[ç—…åã®ãƒªã‚¹ãƒˆ]
            èª¬æ˜ï¼š[ç°¡æ½”ãªèª¬æ˜ã¨ç†ç”±]
            æ³¨æ„ç‚¹ï¼š[è¨ºæ–­ã«ãŠã‘ã‚‹æ³¨æ„ç‚¹ã‚„è¿½åŠ ã§å¿…è¦ãªæ¤œæŸ»ãªã©]

            å¯èƒ½ãªé™ã‚Šå¤šãã®ç—…åã‚’ã€é‘‘åˆ¥è¨ºæ–­ã®è¦³ç‚¹ã‹ã‚‰å¹…åºƒãåˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
            é »åº¦ã®é«˜ã„ã‚‚ã®ã‹ã‚‰ä½ã„ã‚‚ã®ã¾ã§ã€å¯èƒ½æ€§ã®ã‚ã‚‹ç—…åã‚’ç¶²ç¾…çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚
            è€ƒãˆã‚‰ã‚Œã‚‹ç—…åã¯ã€10ã¤ä»¥ä¸ŠæŒ™ã’ã€ãã‚Œãã‚Œã«ã¤ã„ã¦æ ¹æ‹ ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

            æ³¨æ„ï¼šã“ã‚Œã¯åŒ»å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã¯ãªãã€å®Ÿéš›ã®è¨ºæ–­ã«ã¯åŒ»å¸«ã®è¨ºå¯ŸãŒå¿…è¦ã§ã™ã€‚
            """)
        else:
            prompt = ChatPromptTemplate.from_template("""
            You are an expert in diagnosing intractable diseases. Based on the symptoms below, please list all possible names of the disease and briefly explain why in English.

            Patient's symptoms: {input}
            Symptoms translated to English: {english_symptoms}

            Additional information: {additional_context}

            Below is information from relevant medical literature:
            {context}

            Response format:
            Possible diagnoses: [list of conditions]
            Explanation: [concise explanation and reasoning]
            Important notes: [diagnostic considerations or additional tests needed]

            List as many disease names as possible, broadly in terms of differential diagnosis.
            Please provide a comprehensive list of possible disease names, from most frequent to least frequent.
            List at least ten (10) possible disease names and briefly explain the rationale for each.

            Note: This is not medical advice and an actual diagnosis requires consultation with a physician.
            """)

        # æ–‡æ›¸çµåˆãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        document_chain = create_stuff_documents_chain(self.llm, prompt)

        # æ¤œç´¢ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        # è¨ºæ–­ã®å®Ÿè¡Œ
        result = retrieval_chain.invoke({
            "input": symptoms,
            "english_symptoms": english_symptoms,
            "additional_context": additional_context
        })

        if progress_bar:
            progress_bar.progress(1.0, text="è¨ºæ–­å®Œäº†ï¼")

        return result["answer"], english_symptoms, pubmed_info, arxiv_info


# ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
def main():
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2 = st.tabs(["è¨ºæ–­", "ä½¿ã„æ–¹"])
    
    with tab1:
        # ãƒ•ã‚©ãƒ¼ãƒ ã®ä½œæˆ
        with st.form("diagnosis_form"):
            # å…¥åŠ›è¨€èªã¨å‡ºåŠ›è¨€èªã®é¸æŠ
            col1, col2 = st.columns(2)
            with col1:
                source_language = st.selectbox(
                    "å…¥åŠ›ã™ã‚‹ç—‡çŠ¶ã®è¨€èª",
                    ["æ—¥æœ¬èª", "è‹±èª", "ä¸­å›½èª", "éŸ“å›½èª", "ã‚¹ãƒšã‚¤ãƒ³èª", "ãƒ•ãƒ©ãƒ³ã‚¹èª", "ãƒ‰ã‚¤ãƒ„èª"], 
                    index=0
                )
            
            with col2:
                target_language = st.selectbox(
                    "è¨ºæ–­çµæœã®è¨€èª",
                    ["æ—¥æœ¬èª", "è‹±èª"],
                    index=0
                )
                
            # ç—‡çŠ¶ã®å…¥åŠ›
            symptoms = st.text_area("ç—‡çŠ¶ã‚’è©³ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„", height=150)
            
            # æ‚£è€…æƒ…å ±ã®å…¥åŠ›ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
            with st.expander("æ‚£è€…æƒ…å ±ï¼ˆä»»æ„ï¼‰"):
                col1, col2 = st.columns(2)
                with col1:
                    age = st.text_input("å¹´é½¢")
                    gender = st.selectbox("æ€§åˆ¥", ["", "ç”·æ€§", "å¥³æ€§", "ãã®ä»–"])
                    allergies = st.text_input("ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼")
                
                with col2:
                    medical_history = st.text_area("æ—¢å¾€æ­´", height=80)
                    current_medication = st.text_area("ç¾åœ¨æœç”¨ä¸­ã®è–¬", height=80)
            
            # è¨ºæ–­ãƒœã‚¿ãƒ³
            submitted = st.form_submit_button("è¨ºæ–­é–‹å§‹")
    
        # è¨ºæ–­ãŒé–‹å§‹ã•ã‚ŒãŸå ´åˆ
        if submitted:
            if not api_key:
                st.error("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif not symptoms:
                st.error("ç—‡çŠ¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                # æ‚£è€…ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
                patient_data = {
                    "å¹´é½¢": age,
                    "æ€§åˆ¥": gender,
                    "æ—¢å¾€æ­´": medical_history,
                    "ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼": allergies,
                    "ç¾åœ¨ã®è–¬": current_medication
                }
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¡¨ç¤º
                progress_bar = st.progress(0, text="æº–å‚™ä¸­...")
                
                # è¨ºæ–­ãƒœãƒƒãƒˆã®åˆæœŸåŒ–
                try:
                    bot = MultilingualMedicalBot(api_key, model_name)
                    
                    # è¨ºæ–­ã®å®Ÿè¡Œ
                    with st.spinner("è¨ºæ–­ä¸­..."):
                        diagnosis, english_symptoms, pubmed_info, arxiv_info = bot.diagnose(
                            symptoms,
                            patient_data,
                            source_language=source_language,
                            target_language=target_language,
                            progress_bar=progress_bar
                        )
                    
                    # ç¿»è¨³ã•ã‚ŒãŸç—‡çŠ¶ã®è¡¨ç¤º
                    st.subheader("ç—‡çŠ¶ï¼ˆè‹±èªç¿»è¨³ï¼‰")
                    st.info(english_symptoms)
                    
                    # è¨ºæ–­çµæœã®è¡¨ç¤º
                    st.subheader("è¨ºæ–­çµæœ")
                    st.markdown(diagnosis)
                    
                    # å‚ç…§æ–‡çŒ®ã®è¡¨ç¤º
                    with st.expander("å‚ç…§æ–‡çŒ®"):
                        st.subheader("PubMedã®æ–‡çŒ®")
                        if pubmed_info:
                            for doc in pubmed_info:
                                st.markdown(f"**{doc['index']}. {doc['title']}**")
                                st.markdown(f"è‘—è€…: {doc['authors']}")
                                st.markdown(f"å‡ºç‰ˆæ—¥: {doc['pubdate']}")
                                st.markdown("---")
                        else:
                            st.write("PubMedã‹ã‚‰ã®æ–‡çŒ®ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                            
                        st.subheader("ArXivã®æ–‡çŒ®")
                        if arxiv_info:
                            for doc in arxiv_info:
                                st.markdown(f"**{doc['index']}. {doc['title']}**")
                                st.markdown(f"è‘—è€…: {doc['authors']}")
                                st.markdown(f"å‡ºç‰ˆæ—¥: {doc['published']}")
                                st.markdown("---")
                        else:
                            st.write("ArXivã‹ã‚‰ã®æ–‡çŒ®ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    
                    # æ³¨æ„äº‹é …ã®è¡¨ç¤º
                    st.warning("æ³¨æ„: ã“ã‚Œã¯åŒ»å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é©åˆ‡ãªåŒ»ç™‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚")
                    
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    with tab2:
        st.subheader("ä½¿ã„æ–¹")
        st.markdown("""
        ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€å…¥åŠ›ã•ã‚ŒãŸç—‡çŠ¶ã‹ã‚‰è€ƒãˆã‚‰ã‚Œã‚‹ç—…åã‚’ææ¡ˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã§ä½¿ç”¨ã§ãã¾ã™ï¼š
        
        1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è‡ªåˆ†ã®OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
        2. ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™ï¼ˆGPT-3.5ã¾ãŸã¯GPT-4ï¼‰ã€‚
        3. ç—‡çŠ¶ã‚’å…¥åŠ›ã™ã‚‹è¨€èªã¨è¨ºæ–­çµæœã®è¨€èªã‚’é¸æŠã—ã¾ã™ã€‚
        4. ç—‡çŠ¶ã‚’ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è©³ã—ãå…¥åŠ›ã—ã¾ã™ã€‚
        5. å¿…è¦ã«å¿œã˜ã¦æ‚£è€…æƒ…å ±ï¼ˆå¹´é½¢ã€æ€§åˆ¥ã€æ—¢å¾€æ­´ãªã©ï¼‰ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
        6. ã€Œè¨ºæ–­é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
        
        ã‚·ã‚¹ãƒ†ãƒ ã¯å…¥åŠ›ã•ã‚ŒãŸç—‡çŠ¶ã‚’è‹±èªã«ç¿»è¨³ã—ã€PubMedã¨ArXivã‹ã‚‰é–¢é€£ã™ã‚‹åŒ»å­¦è«–æ–‡ã‚’æ¤œç´¢ã—ã¾ã™ã€‚
        AIãŒæ–‡çŒ®ã‚’åˆ†æã—ã€è€ƒãˆã‚‰ã‚Œã‚‹ç—…åã¨ãã®èª¬æ˜ã‚’æä¾›ã—ã¾ã™ã€‚
        
        **é‡è¦ãªæ³¨æ„ç‚¹**ï¼š
        - ã“ã®ãƒ„ãƒ¼ãƒ«ã¯åŒ»å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®ä»£ã‚ã‚Šã«ãªã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        - å®Ÿéš›ã®è¨ºæ–­ã«ã¯å¿…ãšåŒ»ç™‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚
        - APIã‚­ãƒ¼ã¯å®‰å…¨ã«ä¿ç®¡ã•ã‚Œã€ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã•ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        """)
        
        st.subheader("æŠ€è¡“çš„ãªè©³ç´°")
        st.markdown("""
        ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼š
        
        - **Streamlit**: ã‚¦ã‚§ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        - **LangChain**: AIãƒ¢ãƒ‡ãƒ«ã¨ã®ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        - **OpenAI API**: GPT-3.5/GPT-4ã«ã‚ˆã‚‹ç—‡çŠ¶ã®ç¿»è¨³ã¨è¨ºæ–­
        - **PubMed & ArXiv API**: åŒ»å­¦è«–æ–‡ã®æ¤œç´¢
        - **FAISS**: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã‚ˆã‚‹é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã®å–å¾—
        
        ç—‡çŠ¶ã¯æœ€åˆã«è‹±èªã«ç¿»è¨³ã•ã‚Œã€ãã®å¾ŒPubMedã¨ArXivã‹ã‚‰é–¢é€£ã™ã‚‹åŒ»å­¦è«–æ–‡ãŒæ¤œç´¢ã•ã‚Œã¾ã™ã€‚
        ã“ã‚Œã‚‰ã®æ–‡çŒ®ã¯AIãƒ¢ãƒ‡ãƒ«ã«æä¾›ã•ã‚Œã€å¯èƒ½æ€§ã®ã‚ã‚‹è¨ºæ–­ã‚’å°ãå‡ºã™ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
        """)

if __name__ == "__main__":
    main()